# -*- coding: utf-8 -*-
"""investor_view.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13_cBbt2pdHZCoF4N6-7nlIb3qax_JVvy
"""

! pip install pdfplumber
! pip install bert-extractive-summarizer

from pathlib import Path
import pdfplumber
import re
from summarizer import Summarizer

def extract_text_from_pdf(pdf_path):
    text = ""
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            page_text = page.extract_text()
            if page_text:  # Check if there's any text to avoid None errors
                page_text = page_text.encode('ascii', 'ignore').decode('ascii')  # Fix encoding issues
                text += page_text + "\n"
    return text

def extract_speaker_content_without_questions(text):
    """
    Extract only the content spoken by each speaker, ignoring any questions or extra labels.
    This function isolates paragraphs that start with a speaker label (e.g., 'Speaker:') and
    captures the content that follows each speaker's name, but excludes any questions.
    """
    # Pattern to match a speaker's name followed by a colon, then capture content until the next speaker
    speaker_pattern = re.compile(r'([A-Za-z\s]+):\s*(.*?)(?=\n[A-Za-z\s]+:|\Z)', re.DOTALL)

    # Extract speaker content
    speaker_content = []
    for match in speaker_pattern.finditer(text):
        content = match.group(2).strip()  # The content spoken by the speaker
        if '?' not in content:  # Exclude any content containing a question mark
            speaker_content.append(content)

    return "\n\n".join(speaker_content)

def filter_relevant_sentences(text):
    keywords = ["growth", "revenue", "profit", "strategy", "future", "customer", "earnings", "outlook", "new businesses","yoy","qoq","cagr","ebita"]
    sentences = text.split('.')
    relevant_sentences = [sentence for sentence in sentences if any(keyword in sentence.lower() for keyword in keywords)]
    return ". ".join(relevant_sentences)

# Path to the PDF document
pdf_path = Path("/content/SJS Transcript Call.pdf")

# Extract text from the PDF
text = extract_text_from_pdf(pdf_path)

# Filter out questions from the text
answers_only_text = extract_speaker_content_without_questions(text)

#Filter the relevant data from the answers_only_text
filtered_text = filter_relevant_sentences(answers_only_text)

# Initialize BERT-based summarizer
bert_model = Summarizer()


# Summarize the text
summary = bert_model(filtered_text)

file = open("output.txt", "w")
file.write(summary)
file.close()

